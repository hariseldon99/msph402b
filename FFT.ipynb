{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d2b3215",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hariseldon99/msph402b/blob/main/FFT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FcO1zEzhHzN9",
   "metadata": {
    "id": "FcO1zEzhHzN9"
   },
   "source": [
    "All Example Codes for Fast Fourier Transforms\n",
    "==================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RfT6mvr6FbOu",
   "metadata": {
    "id": "RfT6mvr6FbOu"
   },
   "source": [
    "### Instructions: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2099a4",
   "metadata": {},
   "source": [
    "It is suggested that the cell below be run. This cell sets the plot figure size, as well as the font size. Running this cell is optional, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ee1oOswJE4u0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-02-23T11:55:20.066422Z",
     "iopub.status.busy": "2022-02-23T11:55:20.066212Z",
     "iopub.status.idle": "2022-02-23T11:55:20.268351Z",
     "shell.execute_reply": "2022-02-23T11:55:20.267901Z",
     "shell.execute_reply.started": "2022-02-23T11:55:20.066362Z"
    },
    "id": "Ee1oOswJE4u0",
    "outputId": "cbbdd4b9-c67f-441a-8ca3-85c07daba1c2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (8,6)\n",
    "plt.rcParams['font.size'] = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39a59d4-09b9-4636-88f9-596535c15f59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T13:08:23.127952Z",
     "iopub.status.busy": "2022-02-15T13:08:23.127788Z",
     "iopub.status.idle": "2022-02-15T13:08:23.134533Z",
     "shell.execute_reply": "2022-02-15T13:08:23.134107Z",
     "shell.execute_reply.started": "2022-02-15T13:08:23.127936Z"
    },
    "id": "e39a59d4-09b9-4636-88f9-596535c15f59",
    "tags": []
   },
   "source": [
    "**Introduction:**\n",
    "\n",
    "#### The Problem:\n",
    "\n",
    "Generate two time-dependent signals:\n",
    " 1. A sine wave of freauency $100$.\n",
    " 2. A superposition of sine waves of different amplitudes (say, $1$ and $0.3$) and different  frequencies (say $100$ and $70$ respectively).\n",
    " \n",
    "Choose a sampling rate (say $1000$) and build a time vector of signal data by sampling the signals at that rate. Evaluate the Fast Fourier Transform of both signals and plot the absolute values as functions of frequency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac33b3cf-e628-4d67-94dd-c6d9f064f8b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-02-23T11:55:36.504708Z",
     "iopub.status.busy": "2022-02-23T11:55:36.504542Z",
     "iopub.status.idle": "2022-02-23T11:55:37.335608Z",
     "shell.execute_reply": "2022-02-23T11:55:37.335144Z",
     "shell.execute_reply.started": "2022-02-23T11:55:36.504693Z"
    },
    "id": "ac33b3cf-e628-4d67-94dd-c6d9f064f8b8",
    "outputId": "67eebe03-196f-49de-cd92-583e490c59e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "sample_rate = 1000\n",
    "\n",
    "Delta = 1/sample_rate\n",
    "sample_size = 4000\n",
    "t = np.arange(sample_size) * Delta\n",
    "padded_size = 2**np.ceil(np.log2(sample_size)).astype(int)\n",
    "\n",
    "s1 = np.sin(100*t)\n",
    "s2 = s1 + 0.3 * np.sin(70*t)\n",
    "\n",
    "sp1 = np.fft.fft(s1, n=padded_size)\n",
    "sp2 = np.fft.fft(s2, n=padded_size)\n",
    "\n",
    "freq = np.fft.fftfreq(padded_size, d=t[1]-t[0])\n",
    "f, (ax1, ax2) = plt.subplots(2,1)\n",
    "\n",
    "ax1.plot(t[0:600], s1[0:600], \"r.-\", label='sine wave', alpha=0.6)\n",
    "ax1.plot(t[0:600], s2[0:600], \"b\", label='superposition')\n",
    "ax1.set_xlabel('t')\n",
    "\n",
    "ax2.plot(2*np.pi*freq, np.abs(sp1)/np.amax(np.abs(sp1)), \"r.-\", label='sine wave')\n",
    "ax2.plot(2*np.pi*freq, np.abs(sp2)/np.amax(np.abs(sp2)), \"b\", label='superposition')\n",
    "ax2.legend()\n",
    "ax2.set_xlabel('w')\n",
    "ax2.set_xlim(-175,175)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a5cca-b879-48da-a4c4-1db29f076440",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T11:56:02.852687Z",
     "iopub.status.busy": "2022-02-23T11:56:02.852487Z",
     "iopub.status.idle": "2022-02-23T11:56:03.601314Z",
     "shell.execute_reply": "2022-02-23T11:56:03.600756Z",
     "shell.execute_reply.started": "2022-02-23T11:56:02.852671Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "sample_rates = [200, 50, 20, 10]\n",
    "sample_size = 600\n",
    "\n",
    "for s in sample_rates:\n",
    "    Delta = 1/s\n",
    "    t = np.arange(sample_size) * Delta\n",
    "    padded_size = 2**np.ceil(np.log2(sample_size)).astype(int)\n",
    "    signal = np.sin(100*t) + 0.3 * np.sin(70*t)\n",
    "    ft = np.fft.fft(signal, n=padded_size)\n",
    "    freq = np.fft.fftfreq(padded_size, d=t[1]-t[0])\n",
    "    plt.plot(2*np.pi*freq, np.abs(ft)/np.amax(np.abs(ft)),\\\n",
    "             label=f'Sample Rate = {s}')\n",
    "\n",
    "plt.xlabel('t')\n",
    "plt.legend()\n",
    "plt.xlabel('w')\n",
    "plt.xlim(-150,150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d6d638-0659-443e-a162-3ba59dd9606f",
   "metadata": {
    "id": "60d6d638-0659-443e-a162-3ba59dd9606f"
   },
   "source": [
    "#### The Problem:\n",
    "Load the following signal data into numpy arrays:\n",
    "\n",
    " 1. [fftdata/times.npy](fftdata/times.npy)\n",
    " 2. [fftdata/signal.npy](fftdata/signal.npy)\n",
    " 3. [fftdata/noisy_signal.npy](fftdata/noisy_signal.npy)\n",
    "\n",
    "Plot the signal and noisy signal data as functions of time, as well as their FFTs as functions of frequency. \n",
    "\n",
    "\n",
    "First, you'll need to procure these data files and place them where they can be accessed by this notebook. Unless you've cloned the GitHub repository in which this notebook lies, you'll have to do this manually. This can be accomplished by running the code cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e54224",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir fftdata\n",
    "!wget -P fftdata https://github.com/hariseldon99/msph402b/raw/refs/heads/main/fftdata/times.npy\n",
    "!wget -P fftdata https://github.com/hariseldon99/msph402b/raw/refs/heads/main/fftdata/signal.npy\n",
    "!wget -P fftdata https://github.com/hariseldon99/msph402b/raw/refs/heads/main/fftdata/noisy_signal.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ef12dd",
   "metadata": {},
   "source": [
    "If you've cloned this repository locally, you do not need to run the code cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b85a7f2-c128-4a2d-8743-19ab0d96842b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T15:57:10.869549Z",
     "iopub.status.busy": "2022-02-19T15:57:10.869366Z",
     "iopub.status.idle": "2022-02-19T15:57:11.214240Z",
     "shell.execute_reply": "2022-02-19T15:57:11.213760Z",
     "shell.execute_reply.started": "2022-02-19T15:57:10.869517Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (18,9)\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "# Load the datasets from files\n",
    "times = np.load('fftdata/times.npy')\n",
    "signal = np.load('fftdata/signal.npy')\n",
    "noisy_signal = np.load('fftdata/noisy_signal.npy')\n",
    "\n",
    "# Create a 2X2 grid of axes\n",
    "f, axs = plt.subplots(2,2, sharex='col')\n",
    "\n",
    "#Plot the raw datasets on the first column axes\n",
    "axs[0,0].plot(times[0:1000], signal[0:1000], color=\"blue\")\n",
    "axs[0,0].set_title(\"Signal Data\")\n",
    "axs[1,0].plot(times[0:1000], noisy_signal[0:1000],color=\"red\")\n",
    "\n",
    "# Do the FFT of the datasets\n",
    "sample_size = times.shape[-1]\n",
    "padded_size = 2**np.ceil(np.log2(sample_size)).astype(int)\n",
    "ft_sig = np.fft.fft(signal, n=padded_size)\n",
    "ft_noisy = np.fft.fft(noisy_signal, n=padded_size)\n",
    "freq = np.fft.fftfreq(padded_size, d=t[1]-t[0])\n",
    "\n",
    "#Plot the fft datasets on the corresponding rows of the last column\n",
    "axs[0,1].plot(2*np.pi*freq, np.abs(ft_sig), color='blue', label='Pure')\n",
    "axs[0,1].set_title(\"FFT Data\")\n",
    "axs[1,1].plot(2*np.pi*freq, np.abs(ft_noisy), color='red', label='Noisy')\n",
    "for ax in axs[:,1]:\n",
    "    ax.set_xlim(-200,200)\n",
    "    ax.legend()\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea10fd1-c9e5-4f30-8196-5518bc946edb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-02-19T14:40:45.131128Z",
     "iopub.status.busy": "2022-02-19T14:40:45.130958Z",
     "iopub.status.idle": "2022-02-19T14:40:45.311349Z",
     "shell.execute_reply": "2022-02-19T14:40:45.310890Z",
     "shell.execute_reply.started": "2022-02-19T14:40:45.131112Z"
    },
    "id": "7a8d7a0f-e75c-4c84-b1a1-bc79b43dbb4e",
    "outputId": "6ec3e256-cebf-4479-bfb1-4c3bd7c93c06",
    "tags": []
   },
   "source": [
    "Clean up the FFT data of the noisy signal by removing the ‘noisy frequencies’. An easy way to do this is by ‘masking’ the bad data using the masking module in numpy, named ‘numpy.ma’. Finally, take an inverse FFT of the masked data and see if you succeeded in cleaning it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b10ab6a-1fb7-46c2-be93-97c5c6d30380",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-02-19T15:57:16.078131Z",
     "iopub.status.busy": "2022-02-19T15:57:16.077946Z",
     "iopub.status.idle": "2022-02-19T15:57:16.533507Z",
     "shell.execute_reply": "2022-02-19T15:57:16.532850Z",
     "shell.execute_reply.started": "2022-02-19T15:57:16.078099Z"
    },
    "id": "8b10ab6a-1fb7-46c2-be93-97c5c6d30380",
    "outputId": "6b8b482c-99fa-465a-bc9b-67bcbf73b877",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "threshold = 200\n",
    "ft_abs      = np.abs(ft_noisy) \n",
    "indices     = ft_abs > threshold   # filter out those value under 300\n",
    "ft_clean    = indices * ft_noisy # noise frequency will be set to 0\n",
    "cleaned_signal = np.fft.ifft(ft_clean) # Do inverse FFT\n",
    "\n",
    "# Create a 2X2 grid of axes\n",
    "f, axs = plt.subplots(3,2, sharex='col')\n",
    "\n",
    "#Plot the raw datasets on the first column axes\n",
    "axs[0,0].plot(times[0:1000], noisy_signal[0:1000], color='red')\n",
    "axs[0,0].set_title(\"Signal Data\")\n",
    "axs[1,0].plot(times[0:1000], cleaned_signal[0:1000].real, color='green')\n",
    "axs[2,0].plot(times[0:1000], signal[0:1000].real, color='blue')\n",
    "\n",
    "#Plot the fft datasets on the corresponding rows of the last column\n",
    "axs[0,1].plot(2*np.pi*freq, np.abs(ft_noisy), color='red', label='Noisy')\n",
    "axs[0,1].set_title(\"FFT Data\")\n",
    "axs[1,1].plot(2*np.pi*freq, np.abs(ft_clean), color='green', label='Cleaned')\n",
    "axs[2,1].plot(2*np.pi*freq, np.abs(ft_sig), color='blue', label='Pure')\n",
    "for ax in axs[:,1]:\n",
    "    ax.set_xlim(-200,200)\n",
    "    ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877e13c6-bd2b-422a-b497-d2e35943f7ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-02-19T15:13:44.269866Z",
     "iopub.status.busy": "2022-02-19T15:13:44.269676Z",
     "iopub.status.idle": "2022-02-19T15:13:44.450857Z",
     "shell.execute_reply": "2022-02-19T15:13:44.450477Z",
     "shell.execute_reply.started": "2022-02-19T15:13:44.269849Z"
    },
    "id": "78811483-357d-4869-82a2-f9bbba7f4d66",
    "outputId": "e02a932c-8afb-40eb-ebb1-e0a18a4c09c9",
    "tags": []
   },
   "source": [
    "## Exercise 01: \n",
    "\n",
    "Use a similar technique to separate the two frequencies in the cleaned data and plot them \n",
    "Independently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7638b2b-6886-424d-a601-d5760f4f5852",
   "metadata": {},
   "source": [
    "**Comparing DFT with FFT**\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Write (or find) a Python routine that:\n",
    "\n",
    " 1. Takes a numpy array f as its argument. \n",
    " 2. Evaluates the DFT vector F  \n",
    " 3. Evaluates the execution time.\n",
    " 4. Returns both of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51179c9c-d963-4ffd-b36f-6885a7763a56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T17:19:02.722799Z",
     "iopub.status.busy": "2022-02-19T17:19:02.722609Z",
     "iopub.status.idle": "2022-02-19T17:19:02.728192Z",
     "shell.execute_reply": "2022-02-19T17:19:02.727814Z",
     "shell.execute_reply.started": "2022-02-19T17:19:02.722765Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dft(x):\n",
    "    \"\"\"\n",
    "    Function to calculate the \n",
    "    discrete Fourier Transform \n",
    "    of a 1D real-valued signal x\n",
    "    \"\"\"\n",
    "    N = x.shape[-1]\n",
    "    n = np.arange(N)\n",
    "    k = n.reshape((N, 1))\n",
    "    e = np.exp(-2j * np.pi * k * n / N)\n",
    "    return e @ x\n",
    "\n",
    "x = np.random.random(100)\n",
    "print(np.allclose(dft(x), np.fft.fft(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74387c4-0cdd-4a7d-8d0e-ffdb810ddbba",
   "metadata": {},
   "source": [
    "Generate random column vectors of sizes $16, 32, 64, 128, 256, 512,1024, 2048$, and $4096$. Run the above subroutine and plot the execution time as a function of data size. Interpret the curve. Repeat the steps above with the builtin FFT routine. Compare the plots.\n",
    "\n",
    "### Suggestion:\n",
    "\n",
    "Use log-scale for the times in the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d19989e-717c-458d-9b0f-ea1a5da53956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T17:39:29.791346Z",
     "iopub.status.busy": "2022-02-19T17:39:29.790628Z",
     "iopub.status.idle": "2022-02-19T17:40:54.809881Z",
     "shell.execute_reply": "2022-02-19T17:40:54.809400Z",
     "shell.execute_reply.started": "2022-02-19T17:39:29.791324Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (12,9)\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "from timeit import Timer\n",
    "defnum = 20\n",
    "\n",
    "mysetup = 'import numpy as np\\n'\n",
    "mysetup += '''def dft(x):\n",
    "                N = x.shape[-1]\n",
    "                n = np.arange(N)\n",
    "                k = n.reshape((N, 1))\n",
    "                e = np.exp(-2j * np.pi * k * n / N)\n",
    "                return e @ x'''\n",
    "\n",
    "sizes = 2**np.arange(4,13)\n",
    "times_dft = np.zeros_like(sizes)\n",
    "times_fft = np.zeros_like(sizes)\n",
    "for i,s in enumerate(sizes):\n",
    "    dft = Timer(setup=mysetup, stmt=\"dft(np.random.random(%d))\" % (s,))\n",
    "    times_dft[i] = min(dft.repeat(number=defnum)) * 1e6 / defnum\n",
    "    fft = Timer(setup=mysetup, stmt=\"np.fft.fft(np.random.random(%d))\" % (s,))\n",
    "    times_fft[i] = min(fft.repeat(number=defnum)) * 1e6 / defnum\n",
    "\n",
    "plt.plot(sizes, times_dft,label=\"DFT\")\n",
    "plt.plot(sizes, times_fft, label=\"FFT\")\n",
    "plt.xlabel(\"sizes\")\n",
    "plt.ylabel(\"t (mus)\")\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83022758-9b6a-4e31-b2c2-c0b7bed92d55",
   "metadata": {},
   "source": [
    "## Exercise 02:\n",
    "\n",
    " 1. Plot the execution time for the DFT case as a function of $N^2$, where $N$ is the vector size.\n",
    " 2. Plot the execution time for the FFT case as a function of $N\\log_2{N}$.\n",
    " 3. What can you infer from these graphs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34cc962-885c-4fa7-a0da-a0281fef5649",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T10:56:16.522463Z",
     "iopub.status.busy": "2022-02-21T10:56:16.522263Z",
     "iopub.status.idle": "2022-02-21T10:56:16.527416Z",
     "shell.execute_reply": "2022-02-21T10:56:16.526867Z",
     "shell.execute_reply.started": "2022-02-21T10:56:16.522447Z"
    }
   },
   "source": [
    "**Convolutions via FFT**\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Generate two vectors $f$ and $g$ of equal size (choose a large size, preferably a power of $2$), consisting of random numbers, and evaluate the convolution vector $c = f \\otimes g$, where the elements of $c$ are given by\n",
    "\n",
    "\\begin{equation*}\n",
    "c_l = \\sum_j f_{l-j}\\times g_{j}\n",
    "\\end{equation*}\n",
    "\n",
    "1. Imagine that the elements of $f$ lie on a ring. Then, the $l^{th}$ component of $c$ involves the components of $f$ after ‘rolling’ this ring by $l$ places.\n",
    "2. In numpy, there is a function ‘numpy.roll’ that does this. Use that function.\n",
    "\n",
    "Now, get the FFTs of the two vectors, compute their element-wise product, and do the IFFT of the result. Sum over this. Is the sum equal to the previous result? Why? **Hint:** Recall the convolution theorem from the theory of Fourier Transforms. \n",
    "\n",
    "Use the %timeit magic to determine which of the two methods obtained in the previous problem is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a5aaab-5efb-4988-909d-54395866155c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:18:05.833776Z",
     "iopub.status.busy": "2022-02-21T11:18:05.833592Z",
     "iopub.status.idle": "2022-02-21T11:18:22.975944Z",
     "shell.execute_reply": "2022-02-21T11:18:22.975514Z",
     "shell.execute_reply.started": "2022-02-21T11:18:05.833761Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = 2**3\n",
    "f = np.random.random(N)\n",
    "g = np.random.random(N)\n",
    "\n",
    "print(\"Normal Convolution:\")\n",
    "%timeit c = np.array([np.sum(np.roll(f,-l-1)[::-1]*g) for l in range(N)])\n",
    "c = np.array([np.sum(np.roll(f,-l-1)[::-1]*g) for l in range(N)])\n",
    "\n",
    "print(\"\\nConvolution by FFT:\")\n",
    "%timeit c_fft = np.fft.ifft(np.fft.fft(f) * np.fft.fft(g))\n",
    "c_fft = np.fft.ifft(np.fft.fft(f) * np.fft.fft(g))\n",
    "\n",
    "print(\"\\nAre they equal?\", np.allclose(c, c_fft))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8254f9",
   "metadata": {},
   "source": [
    "## Signal Processing with FFT\n",
    "\n",
    "\n",
    "This next exercise involves **processing of digital signals using Fast Fourier Transform**. It will involve listening to sounds, so you might want to setup a pair of headphones (wired or wireless) in order to discern subtle undertones more carefully. \n",
    "\n",
    "The Scientific Python library (`SciPy`) has many modules, classes, and functions available to read data from and write data to a variety of file formats. These are available in `scipy.io`, the Scipy Input-Output submodule. In that submodule, there is a submodule that allows for inter-operation between `NumPy` arrays and sound files, specifically the `Waveform Audio` or `wav` file. Let us import it into our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d68ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d08a8f",
   "metadata": {},
   "source": [
    "Next, download the sample audio files from the repository to your virtual machine. Note that, if you've cloned the repository locally to your computer, you do not need to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac6dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P fftdata https://github.com/hariseldon99/msph402b/raw/refs/heads/main/fftdata/noise_a3s.wav\n",
    "!wget -P fftdata https://github.com/hariseldon99/msph402b/raw/refs/heads/main/fftdata/hum_60_Hz.wav\n",
    "!wget -P fftdata https://github.com/hariseldon99/msph402b/raw/refs/heads/main/fftdata/unknown.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8badb60b",
   "metadata": {},
   "source": [
    "Next we play a wav file named `noise_a3s.wav`.  \n",
    "To play the audio in the file, use the `IPython.display.Audio` submodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212154c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio('fftdata/noise-a3s.wav') # load a local WAV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817bb900",
   "metadata": {},
   "source": [
    "Oops! There is an exception! The `wav` file just contains a bare `NumPy` array with no information on sample rates. Fortunately, those can be calculated by the `wavfile.read()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157be661",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampFreq, sound = wavfile.read('fftdata/noise_a3s.wav')\n",
    "ipd.Audio('fftdata/noise_a3s.wav', rate=sampFreq) # load a local WAV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf7ddf",
   "metadata": {},
   "source": [
    "The audio contains the note **A3#** played by piano and recorded with a microphone. The fundamental frequency (F0) of this note is **233.8 Hz**. There are multiple higher order terms in the Fourier series of the wave amplitude. Theoretically, if the amplitude of an ideally time-periodic signal $s(t)$ is decomposed into a Fourier series as\n",
    "\\begin{equation*}\n",
    "s(t) = c_0 + \\sum_{n\\neq 0} c_n e^{in\\omega t},\n",
    "\\end{equation*}\n",
    "then the $n=\\pm 1$ terms constitute the fundamental mode, with $\\omega$ as the fundamental frequency. The rest are higher order modes, or ***overtones***.\n",
    "\n",
    "**However**, listen to the sound carefully, multiple times, if necessary. There is a corruption in the sound (more audible later on during playback) that sounds like a low frequency (low-pitch) hum ***underneath*** the desired sound, like someone is playing an unwanted low-pitch tune in the background.\n",
    "\n",
    "We need to use FFTs remove this unwanted noise from the signal and obtain a clearer sound. \n",
    "\n",
    "\n",
    "First, some notes on digital audio :\n",
    "\n",
    "* Typically, stereo **wav**-file contains two arrays of integers: for the right and left channel (for your right and left speaker) respectively.\n",
    "* In digital audio, the sound wave of the audio signal is encoded as numerical samples in continuous sequence. \n",
    "* In `WAV` audio, samples are taken $44100$ times per second (the ***sample frequency***) each with a $16$-bit sample depth, ***i.e.***, each number is stored in memory as a digital binary integer (signed) that is $16$ bits wide. \n",
    "* Thus, the range of possible values are $2^{16} = 65536$: ranging from $-32768$ to $32767$. \n",
    "* The file format also allows for the possibility of the more refined $32$-bit sample depth.\n",
    "* The `scipy.io.wavfile.read()` method reads wav files as `int16` (for 16-bit wavs) or `int32` (for 32-bit wavs). We can check the type of the sound as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0a6007",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound.dtype, sampFreq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb8f1e",
   "metadata": {},
   "source": [
    "Clearly, this sound is recorded at a sample frequency of $44100$ and each value is $16-$bits wide, now loaded and stored in the `NumPy` array named `sound`.\n",
    "\n",
    "Next, let us map the amplitude data to the interval $\\left[-1, 1\\right]$. This is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f391dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound = sound / 2.0**15\n",
    "display(sound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70820e72",
   "metadata": {},
   "source": [
    "From the shape of the sound array, we can determine that the wav file has two channels and $45568$ sample points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef5cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adc09e2",
   "metadata": {},
   "source": [
    "Given that the sample rate is given by `sampFreq`, the total signal time can be calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c7c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nchannels = sound.shape\n",
    "signal_time = nsamples/sampFreq\n",
    "print(f\"Signal time is {signal_time} secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cfdbfc",
   "metadata": {},
   "source": [
    "Let us now plot the left and right amplitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cf18eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_array = np.arange(0, nsamples) / sampFreq\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, sharex=True, figsize=(18, 9))\n",
    "\n",
    "axs[0].plot(time_array, sound[:, 0], color='blue')\n",
    "axs[0].set_title('Left Channel')\n",
    "axs[0].set_ylabel('Amplitude')\n",
    "\n",
    "axs[1].plot(time_array, sound[:, 1], color='red')\n",
    "axs[1].set_title('Right Channel')\n",
    "axs[1].set_xlabel('Time [s]')\n",
    "axs[1].set_ylabel('Amplitude');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da072385",
   "metadata": {},
   "source": [
    "You can clearly see that the ideal sound is a periodic wave, but there are distortions from around $0.1$ seconds to $0.7$ seconds (you heard them as  a low-pitched background hum). Now, it should be obvious what to do to get rid of this noise. First, do FFTs and plot the amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d24f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform FFT on both channels\n",
    "fft_left = np.fft.fft(sound[:, 0])\n",
    "fft_right = np.fft.fft(sound[:, 1])\n",
    "\n",
    "# Compute the frequencies corresponding to the FFT values\n",
    "freqs = np.fft.fftfreq(nsamples, 1/sampFreq)\n",
    "\n",
    "# Plot the FFT amplitudes\n",
    "fig, axs = plt.subplots(2, 1, sharex=True, figsize=(18, 9))\n",
    "\n",
    "axs[0].plot(freqs, np.abs(fft_left), color='blue')\n",
    "axs[0].set_title('FFT of Left Channel')\n",
    "axs[0].set_ylabel('Amplitude')\n",
    "\n",
    "axs[1].plot(freqs, np.abs(fft_right), color='red')\n",
    "axs[1].set_title('FFT of Right Channel')\n",
    "axs[1].set_xlabel('Frequency [Hz]')\n",
    "axs[1].set_ylabel('Amplitude')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7652d4d",
   "metadata": {},
   "source": [
    "Although the bandwidth of the human ear is supposed to be 20-Hz to 20-kHz, the frequencies that comprise this sound is well below the upper cutoff, tapering out at around 3-kHz. Let's magnify the by zooming in on a smaller frequency window and changing the amplitude to a decibel-like log-scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d316a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the FFT amplitudes with magnified x range\n",
    "fig, axs = plt.subplots(2, 1, sharex=True, figsize=(18, 9))\n",
    "\n",
    "axs[0].plot(freqs, np.abs(fft_left), color='blue')\n",
    "axs[0].set_title('FFT of Left Channel')\n",
    "axs[0].set_ylabel('Amplitude')\n",
    "axs[0].set_xlim(0, 3800)\n",
    "\n",
    "axs[1].plot(freqs, np.abs(fft_right), color='red')\n",
    "axs[1].set_title('FFT of Right Channel')\n",
    "axs[1].set_xlabel('Frequency [Hz]')\n",
    "axs[1].set_ylabel('Amplitude')\n",
    "axs[1].set_xlim(0, 3800)\n",
    "axs[0].set_yscale('log')\n",
    "axs[1].set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ede63d4",
   "metadata": {},
   "source": [
    "\n",
    "Notice that the plot exhibits a significant spike around $60$-Hz, which corresponds to the AC frequency standard in Canada, where the recording was made. This frequency is quite noticeable during playback. In contrast, India uses a $50$-Hz standard.\n",
    "\n",
    "This phenomenon, known as **electric hum**, results from pervasive AC electromagnetic fields from nearby devices and wiring. This $60$-Hz noise infiltrates audio systems, getting recorded via microphones. Interestingly, when using a laptop's built-in microphone, disconnecting the charger can help mitigate this interference.\n",
    "\n",
    "To perceive this aurally, play the pure $60-Hz$ audio signal from the downloaded audio files and compare with the running sound file. Play them at a slower playback speed, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faef6c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio('fftdata/noise_a3s.wav', rate=sampFreq) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497707e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio('fftdata/hum_60_Hz.wav') # load a local WAV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a4f323",
   "metadata": {},
   "source": [
    "Also, notice that the second prominent peak is at around **233 Hz**. This should be the fundamental frequency, while the other peaks are overtones. Besides the $60$-Hz noise, we observe peaks at around $233$-Hz, $465$-Hz, $698$-Hz, etc., all approximately multiples of $233$-Hz.\n",
    "\n",
    "Note that the best way to determine these peak positions is by using a **peak-fitting library** like [`lmfit`](https://lmfit.github.io/lmfit-py/) on the audio dataset. In the interest of simplicity, however, we choose to eyeball the peak positions here. Interested participants might check the [Built-in fitting models](https://lmfit.github.io/lmfit-py/builtin_models.html) available with `lmfit` for details.\n",
    "\n",
    "In any case, the remainder of the task should now be obvious. Just delete amplitude data around $60$-Hz. For good measure, also delete any ultrasonic data above $20$-KHz, as well as subsonic data below $20$-Hz. We can't hear those anyway. Removing those redundant sounds can help ***compress*** the audio file better, an added bonus of FFT! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2932b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Masks for the included frequencies\n",
    "included_idx = np.array([np.abs(f) > 62 or np.abs(f) < 58 for f in freqs])\n",
    "audible_idx = np.array([np.abs(f) <= 20000 and np.abs(f) >= 20 for f in freqs])\n",
    "fft_left_clean = fft_left * included_idx * audible_idx\n",
    "fft_right_clean = fft_right * included_idx * audible_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "noiseless_left = np.fft.ifft(fft_left_clean)\n",
    "noiseless_right = np.fft.ifft(fft_right_clean)\n",
    "\n",
    "#Stack the left and right sounds\n",
    "noiseless_sound = np.column_stack((noiseless_left, noiseless_right))\n",
    "\n",
    "# Re-scale back to integers\n",
    "noiseless_sound = np.round(noiseless_sound * 2.0**15).astype(np.int16)\n",
    "wavfile.write('fftdata/noiseless_output.wav', sampFreq, noiseless_sound) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b131976f",
   "metadata": {},
   "source": [
    "Now, aurally compare the new noiseless audio with the original noise audio and hear the difference for yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01358c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio('fftdata/noiseless_output.wav', rate=sampFreq) # load the file and play it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920072cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio('fftdata/noise_a3s.wav', rate=sampFreq) # load a local WAV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b48051",
   "metadata": {},
   "source": [
    "Finally, let us devise a quick and dirty way to use some signal processing techniques and estimate the dominant frequency in a given time-series signal. The basic steps are:\n",
    "\n",
    "* Do FFT and find a crude estimate of the peak from the maximum value.\n",
    "* Use the [Blackman-Harris window](https://www.recordingblogs.com/wiki/blackman-harris-window), together with (inverted) parabolic interpolation, to find a more refined estimate of the peak. See [Quadratic Interpolation of Spectral Peaks](https://ccrma.stanford.edu/~jos/sasp/Quadratic_Interpolation_Spectral_Peaks.html) for details. The [Blackman-Harris window](https://www.recordingblogs.com/wiki/blackman-harris-window) is basically a way to extract a chunk of the signal continuously by weighing it with the following tempered function\n",
    "  \\begin{equation*}\n",
    "    \\begin{gathered}\n",
    "    a(k)=0.35875-0.48829 \\cos \\left(\\frac{2 \\pi k}{N-1}\\right)+0.14128 \\cos \\left(\\frac{4 \\pi k}{N-1}\\right) \\\\\n",
    "    -0.01168 \\cos \\left(\\frac{6 \\pi k}{N-1}\\right).\n",
    "    \\end{gathered}\n",
    "  \\end{equation*}\n",
    "Here, $N$ is the length of the window, and $k\\in [0,1,2\\cdots, N-1]$. The `scipy.signal.windows` module has a built-in `blackmanharris` function that we can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e987d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal.windows import blackmanharris\n",
    "window = blackmanharris(201)\n",
    "plt.plot(window)\n",
    "plt.title(\"Blackman-Harris window\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.xlabel(\"Sample\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2854748e",
   "metadata": {},
   "source": [
    "Here are two functions, one that does the parabolic interpolation, and the other that FFT's a signal and uses the Blackman-harris window, together with the parabolic routine, to estimate the peak frequency position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b44db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "from numpy.fft import rfft\n",
    "from numpy import argmax, log\n",
    "from scipy.signal.windows import blackmanharris\n",
    "\n",
    "def parabolic(f, x):\n",
    "    \"\"\"Quadratic interpolation for estimating the true position of an\n",
    "    inter-sample maximum when nearby samples are known.\n",
    "    f is a vector and x is an index for that vector.\n",
    "    Returns (vx, vy), the coordinates of the vertex of a parabola that goes\n",
    "    through point x and its two neighbors.\n",
    "    Example:[Blackman-Harris window](https://www.recordingblogs.com/wiki/blackman-harris-window)\n",
    "    Defining a vector f with a local maximum at index 3 (= 6), find local\n",
    "    maximum if points 2, 3, and 4 actually defined a parabola.\n",
    "    In [3]: f = [2, 3, 1, 6, 4, 2, 3, 1]\n",
    "    In [4]: parabolic(f, argmax(f))\n",
    "    Out[4]: (3.2142857142857144, 6.1607142857142856)\n",
    "    \"\"\"\n",
    "    xv = 1/2. * (f[x-1] - f[x+1]) / (f[x-1] - 2 * f[x] + f[x+1]) + x\n",
    "    yv = f[x] - 1/4. * (f[x-1] - f[x+1]) * (xv - x)\n",
    "    return (xv, yv)\n",
    "\n",
    "\n",
    "def freq_from_fft(sig, fs):\n",
    "    \"\"\"\n",
    "    Estimate frequency from peak of FFT\n",
    "    \"\"\"\n",
    "    # Compute Fourier transform of windowed signal\n",
    "    windowed = sig * blackmanharris(len(sig))\n",
    "    f = rfft(windowed)\n",
    "\n",
    "    # Find the peak and interpolate to get a more accurate peak\n",
    "    i = argmax(abs(f))  # Just use this for less-accurate, naive version\n",
    "    #true_i = i\n",
    "    true_i = parabolic(log(abs(f)), i)[0]\n",
    "\n",
    "    # Convert to equivalent frequency\n",
    "    return fs * true_i / len(windowed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50778b6",
   "metadata": {},
   "source": [
    "Now, use this function to get the dominant frequency of the noisy and noise-free signal and check..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b1ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampFreq, sound = wavfile.read('fftdata/noise_a3s.wav')\n",
    "left_sound = sound[:, 0]\n",
    "right_sound = sound[:, 1]\n",
    "freq_from_fft(left_sound, sampFreq), freq_from_fft(right_sound, sampFreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089230e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampFreq, sound = wavfile.read('fftdata/noiseless_output.wav')\n",
    "left_sound = sound[:, 0]\n",
    "right_sound = sound[:, 1]\n",
    "freq_from_fft(left_sound, sampFreq), freq_from_fft(right_sound, sampFreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8904964f",
   "metadata": {},
   "source": [
    "The noisy signal gives the electric hum as the dominant frequency, whereas the FFT-cleaned signal gives the correct fundamental mode.\n",
    "\n",
    "**Note:** This method has a drawback, that it doesn't find the right value if the overtones are stronger than fundamental (then it'll mistakenly pick up the strongest overtone). In that case, more sophisticated techniques are needed. Fortunately, in our case, the overtones are weaker than the fundamental.\n",
    "\n",
    "### Homework\n",
    "\n",
    "As an added bonus, the noiseless file compresses better due to a lot of the unnecessary data being set to zero. To see this in a simple way, download both the noise audio and noiseless audio to your local computer, zip them and check the respective file sizes!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d466d596",
   "metadata": {},
   "source": [
    "## Spectograms and FFT\n",
    "\n",
    "\n",
    "A spectrogram is a graph that displays the strength of a signal over time for a given frequency range. Using a color spectrum, it points to the frequencies where the signal’s energy is highest and shows the energy variation over time.\n",
    "\n",
    "\n",
    "For a time-dependent vibration signal, a spectrogram’s color scale identifies the frequencies of a waveform’s amplitude peaks over time. Unlike a time or frequency graph, a spectrogram correlates peak values to time and frequency. Spectrograms can be used to analyze the frequency content of a continuous waveform, locating strong signals and determining how the vibration behavior changes over time.\n",
    "\n",
    "\n",
    "Thus, spectrograms are visual representations of audio – representing time, frequency, and amplitude all on one graph.  Spectrograms are actually created using `Short-time Fourier Transform` `(STFT)`. The idea is that we divide the audio signal into small pieces and then the FFT of each piece is plotted on the graph against time.\n",
    "\n",
    "\n",
    "As it happens, the `matplotlib` plotting library has a `specgram()` method that accomplishes the STFT automatically, requiring little bioler-plate coding. As a simple illustration, let us do a spectogram of a single sine wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b0568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Number of sample points. \n",
    "#Too many sample points you risk 'oversampling' the signal\n",
    "# While oversampling doesn't introduce errors, it can decrease the frequency resolution of your FFT.\n",
    "ntotal = 5000\n",
    "\n",
    "signal_freq = 25\n",
    "# Generating an array of values\n",
    "times = np.linspace(0, 50, ntotal)\n",
    "dt = times[1] - times[0]\n",
    "\n",
    "# Actual data array which needs to be plot\n",
    "signal = 20*(np.sin(2 * np.pi * signal_freq * times))\n",
    "\n",
    "# Matplotlib.pyplot.specgram() function to\n",
    "# generate spectrogram\n",
    "plt.specgram(signal, Fs=1/dt, cmap=\"rainbow\")\n",
    "plt.colorbar(label='Intensity [dB]')\n",
    "\n",
    "# Set the title of the plot, xlabel and ylabel\n",
    "# and display using show() function\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"Frequencies (Hz)\")\n",
    "\n",
    "#Theoretical peak position at signal_freq\n",
    "plt.axhline(signal_freq, color='black', linestyle='--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47e2e4f",
   "metadata": {},
   "source": [
    "The keyword argument `Fs` takes the sampling frequency (samples per time unit). It is used to calculate the Fourier frequencies, freqs, in cycles per time unit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be07a229",
   "metadata": {},
   "source": [
    "By default, the `specgram()` method uses $256$ data points for each 'block', or chunk, for the FFT. This can be changed using the `NFFT` keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a540f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#More sample points\n",
    "ntotal = 5000\n",
    "\n",
    "signal_freq = 25\n",
    "# Generating an array of values\n",
    "times = np.linspace(0, 50, ntotal)\n",
    "dt = times[1] - times[0]\n",
    "\n",
    "# Actual data array which needs to be plot\n",
    "signal = 20*(np.sin(2 * np.pi * signal_freq * times))\n",
    "\n",
    "\n",
    "# Matplotlib.pyplot.specgram() function to\n",
    "# generate spectrogram\n",
    "plt.specgram(signal, Fs=1/dt, cmap=\"rainbow\", NFFT=512)\n",
    "plt.colorbar(label='Intensity [dB]')\n",
    "\n",
    "# Set the title of the plot, xlabel and ylabel\n",
    "# and display using show() function\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"Frequencies (Hz)\")\n",
    "\n",
    "#Theoretical peak position at signal_freq\n",
    "plt.axhline(signal_freq, color='black', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1c64c6",
   "metadata": {},
   "source": [
    "Note that the spectogram will not correspond exactly with that predicted by naive Fourier theory. This happens, in large part, due to each chunk being selected according to a weighed windowing routine by `specgram()`. This is done through the `window` keyword argument, which is a Hanning window function by default. Let's change it to `window_none` and see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe924a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.mlab import window_none\n",
    "# Matplotlib.pyplot.specgram() function to\n",
    "# generate spectrogram\n",
    "plt.specgram(signal, Fs=1/dt, cmap=\"rainbow\", NFFT=1024, window=window_none)\n",
    "plt.colorbar(label='Intensity [dB]')\n",
    "\n",
    "# The gca(), or 'get current axis' method yieds the running axis object\n",
    "plt.gca().xaxis.set_ticks_position('both')\n",
    "plt.gca().yaxis.set_ticks_position('both')\n",
    "plt.gca().xaxis.set_tick_params(which='both', labelbottom=True, labeltop=True)\n",
    "plt.gca().yaxis.set_tick_params(which='both', labelleft=True, labelright=True)\n",
    "# Set the title of the plot, xlabel and ylabel\n",
    "# and display using show() function\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"Frequencies (Hz)\")\n",
    "\n",
    "\n",
    "#Theoretical peak position at signal_freq\n",
    "plt.axhline(signal_freq, color='black', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e9a38",
   "metadata": {},
   "source": [
    "Finally, let us get a spectogram of that noisy sound from before, and compare side-by-side with the noise-filtered one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f27546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.io import wavfile\n",
    "noisy_sampFreq, noisy_sound = wavfile.read('fftdata/noise_a3s.wav')\n",
    "\n",
    "clean_sampFreq, clean_sound = wavfile.read('fftdata/noiseless_output.wav')\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "# Matplotlib.pyplot.specgram() function to\n",
    "# generate spectrogram\n",
    "ax0.specgram(noisy_sound[:,0], Fs=noisy_sampFreq, cmap=\"rainbow\", window=window_none)\n",
    "ax0.set_title('Noisy Signal')\n",
    "ax1.set_ylabel('Frequencies [Hz]')\n",
    "\n",
    "ax1.specgram(clean_sound[:,0], Fs=clean_sampFreq, cmap=\"rainbow\", window=window_none)\n",
    "ax1.set_title('Cleaned Signal')\n",
    "ax1.set_xlabel('Time [s]')\n",
    "ax1.set_ylabel('Frequencies [Hz]')\n",
    "\n",
    "#Zoom in on and mark the fundamental mode and first few overtones\n",
    "fudamental_freq = freq_from_fft(clean_sound[:,0], clean_sampFreq)\n",
    "modes = [1,2,3]\n",
    "for ax in (ax0, ax1):\n",
    "    ax.set_ylim(0, 1.5 * modes[-1] *fudamental_freq)\n",
    "\n",
    "for m in modes:\n",
    "    ax1.axhline(m * fudamental_freq, color='black', linestyle='--', alpha=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a387e71",
   "metadata": {},
   "source": [
    "As you can see, sound is a lot cleaner, with the electric hum and subsonic frequencies gone, and the prominent sound at the fundamental mode is much more visible.\n",
    "\n",
    "This type of signal filtering is very basic, and there are more sophisticated techniques that yield better results, including those involving artificial intelligence. Nonetheless, all of them involve FFTs, either directly or indirectly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7df32",
   "metadata": {},
   "source": [
    "## Exercise 03: Spectrogram using FFT\n",
    "1. Generate a signal that consists of two sine waves with different frequencies that change very slowly over time (say, linearly). Use a sampling rate of 1000 Hz.\n",
    "2. Compute the spectrogram of the signal using FFT. Plot the spectrogram to visualize how the frequency content of the signal changes over time.\n",
    "\n",
    "\n",
    "## Exercise 04: FFT of Real-World Data\n",
    "\n",
    "In the file named `fftdata/unknown.wav`, find the fundamental frequency and remove all the overtones form the Fourier spectrum. Restore the original sound, save it with the filename `fftdata/no_overtones.wav` and play the sound to hear if you like it. Why are overtones so important?\n",
    "\n",
    "**Hints:** \n",
    "   1. Compare the sounds of a sitar and guitar.\n",
    "   2. It might be a good idea to amplify the FFTs by a factor of, say 10, so that the sound amplitude goes up to hearing level."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Integration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "hpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
